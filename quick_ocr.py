#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
Quick OCR - ç®€åŒ–çš„OCRå‘½ä»¤è¡Œå·¥å…·
åŸºäº pytorch_paddle.py å°è£…ï¼Œæä¾›ç®€æ´çš„å‘½ä»¤è¡Œæ¥å£å’Œå¯è§†åŒ–è¾“å‡º
"""

import os
import sys
import cv2
import time
import json
import argparse
import numpy as np
from PIL import Image, ImageDraw
from typing import List

# æ·»åŠ é¡¹ç›®è·¯å¾„
__dir__ = os.path.dirname(os.path.abspath(__file__))
sys.path.append(__dir__)

# å¯¼å…¥æˆ‘ä»¬çš„OCRç±»
from pytorch_paddle import PytorchPaddleOCR

# å¯¼å…¥å·¥å…·å‡½æ•°
sys.path.append(os.path.abspath(os.path.join(__dir__, 'tools/infer')))
sys.path.append(os.path.abspath(os.path.join(__dir__, 'pytorchocr/utils')))

from utility import get_image_file_list, check_and_read
from pytorchocr_utility import draw_ocr_box_txt


def parse_args():
    """è§£æå‘½ä»¤è¡Œå‚æ•°"""
    parser = argparse.ArgumentParser(description="Quick OCR - ç®€åŒ–çš„OCRå‘½ä»¤è¡Œå·¥å…·")
    
    # è¾“å…¥è¾“å‡ºå‚æ•°
    parser.add_argument('--image_dir', type=str, required=True, help='å›¾åƒæ–‡ä»¶æˆ–ç›®å½•è·¯å¾„')
    parser.add_argument('--output_dir', type=str, default='./inference_results', 
                       help='è¾“å‡ºç›®å½•ï¼Œé»˜è®¤: ./inference_results')
    
    # è®¾å¤‡å‚æ•°
    parser.add_argument('--use_npu', type=str, default='true', 
                       help='æ˜¯å¦ä½¿ç”¨NPUï¼Œé»˜è®¤: true')
    parser.add_argument('--npu_device_id', type=int, default=0, 
                       help='NPUè®¾å¤‡IDï¼Œé»˜è®¤: 0')
    
    # æ¨¡å‹å‚æ•°
    parser.add_argument('--det_model_path', type=str, default='./models/ptocr_v5_server_det.pth',
                       help='æ£€æµ‹æ¨¡å‹è·¯å¾„')
    parser.add_argument('--rec_model_path', type=str, default='./models/ptocr_v5_server_rec.pth',
                       help='è¯†åˆ«æ¨¡å‹è·¯å¾„')
    parser.add_argument('--rec_char_dict_path', type=str, default='./pytorchocr/utils/dict/ppocrv5_dict.txt',
                       help='å­—ç¬¦å­—å…¸è·¯å¾„')
    parser.add_argument('--rec_image_shape', type=str, default='3,48,320',
                       help='è¯†åˆ«å›¾åƒå°ºå¯¸')
    
    # è§’åº¦åˆ†ç±»å‚æ•°
    parser.add_argument('--use_angle_cls', type=str, default='true',
                       help='æ˜¯å¦ä½¿ç”¨è§’åº¦åˆ†ç±»ï¼Œé»˜è®¤: true')
    parser.add_argument('--cls_model_path', type=str, default='./models/ch_ptocr_mobile_v2.0_cls_infer.pth',
                       help='è§’åº¦åˆ†ç±»æ¨¡å‹è·¯å¾„')
    
    # æ£€æµ‹å‚æ•°
    parser.add_argument('--det_limit_type', type=str, default='min',
                       help='æ£€æµ‹é™åˆ¶ç±»å‹ï¼Œé»˜è®¤: min')
    parser.add_argument('--det_db_thresh', type=float, default=0.12,
                       help='DBæ£€æµ‹é˜ˆå€¼ï¼Œé»˜è®¤: 0.12')
    parser.add_argument('--det_db_box_thresh', type=float, default=0.15,
                       help='DBè¾¹ç•Œæ¡†é˜ˆå€¼ï¼Œé»˜è®¤: 0.15')
    parser.add_argument('--det_db_unclip_ratio', type=float, default=1.8,
                       help='DBåè£å‰ªæ¯”ä¾‹ï¼Œé»˜è®¤: 1.8')
    parser.add_argument('--use_dilation', type=str, default='true',
                       help='æ˜¯å¦ä½¿ç”¨è†¨èƒ€æ“ä½œï¼Œé»˜è®¤: true')
    
    # å…¶ä»–å‚æ•°
    parser.add_argument('--drop_score', type=float, default=0.0,
                       help='ç½®ä¿¡åº¦é˜ˆå€¼ï¼Œé»˜è®¤: 0.0')
    parser.add_argument('--vis_font_path', type=str, default='./doc/fonts/simfang.ttf',
                       help='å¯è§†åŒ–å­—ä½“è·¯å¾„')
    parser.add_argument('--save_txt_results', type=str, default='true',
                       help='æ˜¯å¦ä¿å­˜æ–‡æœ¬ç»“æœï¼Œé»˜è®¤: true')
    parser.add_argument('--save_visual_results', type=str, default='true',
                       help='æ˜¯å¦ä¿å­˜å¯è§†åŒ–ç»“æœï¼Œé»˜è®¤: true')
    
    return parser.parse_args()


def str_to_bool(v):
    """å­—ç¬¦ä¸²è½¬å¸ƒå°”å€¼"""
    if isinstance(v, bool):
        return v
    if v.lower() in ('yes', 'true', 't', 'y', '1'):
        return True
    elif v.lower() in ('no', 'false', 'f', 'n', '0'):
        return False
    else:
        raise argparse.ArgumentTypeError('Boolean value expected.')


def create_ocr_instance(args):
    """åˆ›å»ºOCRå®ä¾‹"""
    print("ğŸš€ åˆå§‹åŒ–OCRå®ä¾‹...")
    
    # è½¬æ¢å­—ç¬¦ä¸²å‚æ•°ä¸ºå¸ƒå°”å€¼
    use_npu = str_to_bool(args.use_npu)
    use_angle_cls = str_to_bool(args.use_angle_cls)
    use_dilation = str_to_bool(args.use_dilation)
    
    try:
        ocr = PytorchPaddleOCR(
            use_npu=use_npu,
            npu_device_id=args.npu_device_id,
            det_model_path=args.det_model_path,
            rec_model_path=args.rec_model_path,
            rec_char_dict_path=args.rec_char_dict_path,
            rec_image_shape=args.rec_image_shape,
            use_angle_cls=use_angle_cls,
            cls_model_path=args.cls_model_path,
            drop_score=args.drop_score,
            # æ£€æµ‹å‚æ•°
            det_limit_type=args.det_limit_type,
            det_db_thresh=args.det_db_thresh,
            det_db_box_thresh=args.det_db_box_thresh,
            det_db_unclip_ratio=args.det_db_unclip_ratio,
            use_dilation=use_dilation,
        )
        
        print("âœ… OCRå®ä¾‹åˆå§‹åŒ–æˆåŠŸ")
        print(f"   è®¾å¤‡: {'NPU' if use_npu else 'CPU'}")
        print(f"   è§’åº¦åˆ†ç±»: {'å¯ç”¨' if use_angle_cls else 'ç¦ç”¨'}")
        print(f"   ç½®ä¿¡åº¦é˜ˆå€¼: {args.drop_score}")
        return ocr
        
    except Exception as e:
        print(f"âŒ OCRå®ä¾‹åˆå§‹åŒ–å¤±è´¥: {e}")
        sys.exit(1)


def save_visualization(image_path, dt_boxes, rec_res, output_dir, font_path, drop_score):
    """ä¿å­˜å¯è§†åŒ–ç»“æœ"""
    try:
        # è¯»å–åŸå›¾
        img = cv2.imread(image_path)
        if img is None:
            print(f"âš ï¸  æ— æ³•è¯»å–å›¾åƒ: {image_path}")
            return None
            
        # è½¬æ¢ä¸ºPILå›¾åƒ
        image = Image.fromarray(cv2.cvtColor(img, cv2.COLOR_BGR2RGB))
        
        # æ£€æŸ¥æ˜¯å¦æœ‰OCRç»“æœ
        has_results = (dt_boxes is not None and 
                      len(dt_boxes) > 0 and 
                      rec_res is not None and 
                      len(rec_res) > 0)
        
        if has_results:
            # å‡†å¤‡æ•°æ®
            boxes = dt_boxes
            texts = [res['text'] for res in rec_res]
            scores = [res['confidence'] for res in rec_res]
            
            # ç»˜åˆ¶OCRç»“æœ
            draw_img = draw_ocr_box_txt(
                image, boxes, texts, scores, 
                drop_score=drop_score, font_path=font_path
            )
        else:
            # å¦‚æœæ²¡æœ‰æ£€æµ‹ç»“æœï¼Œè¿”å›åŸå›¾
            draw_img = np.array(image)
        
        # ä¿å­˜å›¾åƒ
        filename = os.path.basename(image_path)
        save_path = os.path.join(output_dir, f"vis_{filename}")
        cv2.imwrite(save_path, draw_img[:, :, ::-1])  # RGBè½¬BGR
        
        return save_path
        
    except Exception as e:
        print(f"âš ï¸  ä¿å­˜å¯è§†åŒ–ç»“æœå¤±è´¥: {e}")
        return None


def process_single_image(ocr, image_path, output_dir, args):
    """å¤„ç†å•å¼ å›¾åƒ"""
    print(f"\nğŸ“¸ å¤„ç†å›¾åƒ: {os.path.basename(image_path)}")
    
    start_time = time.time()
    
    try:
        # OCRè¯†åˆ«
        results = ocr.ocr(image_path)
        
        # è½¬æ¢ä¸ºpredict_system.pyæ ¼å¼çš„ç»“æœ
        dt_boxes = []
        rec_res = []
        
        if results:
            for result in results:
                # è½¬æ¢bboxæ ¼å¼
                bbox = np.array(result['bbox'])
                dt_boxes.append(bbox)
                rec_res.append(result)
        
        # åªæœ‰å½“æœ‰ç»“æœæ—¶æ‰è½¬æ¢ä¸ºnumpyæ•°ç»„
        if dt_boxes:
            dt_boxes = np.array(dt_boxes)
        else:
            dt_boxes = None
        
        elapsed_time = time.time() - start_time
        
        # è¾“å‡ºè¯†åˆ«ç»“æœ
        if rec_res:
            print(f"âœ… è¯†åˆ«å®Œæˆï¼Œç”¨æ—¶: {elapsed_time:.3f}sï¼Œè¯†åˆ«åˆ° {len(rec_res)} ä¸ªæ–‡æœ¬åŒºåŸŸ")
            for i, result in enumerate(rec_res):
                print(f"   {i+1}. {result['text']} (ç½®ä¿¡åº¦: {result['confidence']:.3f})")
        else:
            print(f"âš ï¸  æœªæ£€æµ‹åˆ°æ–‡æœ¬å†…å®¹ï¼Œç”¨æ—¶: {elapsed_time:.3f}s")
        
        # ä¿å­˜å¯è§†åŒ–ç»“æœ
        vis_path = None
        if str_to_bool(args.save_visual_results):
            vis_path = save_visualization(
                image_path, dt_boxes, rec_res, output_dir, 
                args.vis_font_path, args.drop_score
            )
            if vis_path:
                print(f"ğŸ–¼ï¸  å¯è§†åŒ–ç»“æœå·²ä¿å­˜: {vis_path}")
        
        # å‡†å¤‡ä¿å­˜çš„ç»“æœ
        save_result = {
            'image_path': image_path,
            'results': []
        }
        
        if rec_res:
            for result in rec_res:
                save_result['results'].append({
                    "transcription": result['text'],
                    "points": result['bbox'],
                    "confidence": result['confidence']
                })
        
        return save_result, elapsed_time
        
    except Exception as e:
        print(f"âŒ å¤„ç†å›¾åƒå¤±è´¥: {e}")
        return None, 0


def main():
    """ä¸»å‡½æ•°"""
    args = parse_args()
    
    print("=" * 60)
    print("ğŸ”¥ Quick OCR - ç®€åŒ–çš„OCRå‘½ä»¤è¡Œå·¥å…·")
    print("=" * 60)
    
    # åˆ›å»ºè¾“å‡ºç›®å½•
    os.makedirs(args.output_dir, exist_ok=True)
    
    # åˆ›å»ºOCRå®ä¾‹
    ocr = create_ocr_instance(args)
    
    # è·å–å›¾åƒæ–‡ä»¶åˆ—è¡¨
    image_file_list = get_image_file_list(args.image_dir)
    
    if not image_file_list:
        print(f"âŒ åœ¨ {args.image_dir} ä¸­æœªæ‰¾åˆ°å›¾åƒæ–‡ä»¶")
        sys.exit(1)
    
    print(f"\nğŸ“‚ å‘ç° {len(image_file_list)} ä¸ªå›¾åƒæ–‡ä»¶")
    
    # å¤„ç†å›¾åƒ
    all_results = []
    total_time = 0
    total_time_exclude_first = 0  # æ’é™¤é¦–å¼ å›¾ç‰‡çš„æ€»æ—¶é—´
    success_count = 0
    first_image_time = 0  # é¦–å¼ å›¾ç‰‡çš„å¤„ç†æ—¶é—´
    
    start_batch_time = time.time()
    
    for idx, image_file in enumerate(image_file_list):
        print(f"\n[{idx+1}/{len(image_file_list)}]", end="")
        
        result, elapsed = process_single_image(ocr, image_file, args.output_dir, args)
        
        if result:
            all_results.append(result)
            success_count += 1
        
        total_time += elapsed
        
        # è®°å½•é¦–å¼ å›¾ç‰‡æ—¶é—´ï¼Œä»ç¬¬äºŒå¼ å¼€å§‹ç´¯è®¡æ’é™¤é¦–å¼ çš„æ—¶é—´
        if idx == 0:
            first_image_time = elapsed
        else:
            total_time_exclude_first += elapsed
    
    batch_time = time.time() - start_batch_time
    
    # ä¿å­˜æ–‡æœ¬ç»“æœ
    if str_to_bool(args.save_txt_results) and all_results:
        results_file = os.path.join(args.output_dir, "ocr_results.json")
        with open(results_file, 'w', encoding='utf-8') as f:
            json.dump(all_results, f, ensure_ascii=False, indent=2)
        print(f"\nğŸ’¾ æ–‡æœ¬ç»“æœå·²ä¿å­˜: {results_file}")
        
        # åŒæ—¶ä¿å­˜ç®€åŒ–çš„æ–‡æœ¬æ–‡ä»¶
        txt_file = os.path.join(args.output_dir, "ocr_results.txt")
        with open(txt_file, 'w', encoding='utf-8') as f:
            for result in all_results:
                filename = os.path.basename(result['image_path'])
                f.write(f"{filename}\n")
                for item in result['results']:
                    f.write(f"  {item['transcription']} (ç½®ä¿¡åº¦: {item['confidence']:.3f})\n")
                f.write("\n")
        print(f"ğŸ“„ ç®€åŒ–æ–‡æœ¬ç»“æœå·²ä¿å­˜: {txt_file}")
    
    # è¾“å‡ºç»Ÿè®¡ä¿¡æ¯
    print("\n" + "=" * 60)
    print("ğŸ“Š å¤„ç†ç»Ÿè®¡")
    print("=" * 60)
    print(f"æ€»å›¾åƒæ•°: {len(image_file_list)}")
    print(f"æˆåŠŸå¤„ç†: {success_count}")
    print(f"å¤±è´¥æ•°é‡: {len(image_file_list) - success_count}")
    print(f"æ€»è€—æ—¶: {batch_time:.3f}s")
    
    # è®¡ç®—å¹³å‡è€—æ—¶ï¼ˆæ’é™¤é¦–å¼ å›¾ç‰‡çš„é¢„çƒ­æ—¶é—´ï¼‰
    if len(image_file_list) > 1:
        avg_time_exclude_first = total_time_exclude_first / (len(image_file_list) - 1)
        print(f"é¦–å¼ å›¾ç‰‡è€—æ—¶: {first_image_time:.3f}s (åŒ…å«æ¨¡å‹é¢„çƒ­)")
        print(f"å¹³å‡è€—æ—¶ (æ’é™¤é¦–å¼ ): {avg_time_exclude_first:.3f}s/å›¾")
    else:
        print(f"å¹³å‡è€—æ—¶: {total_time/len(image_file_list):.3f}s/å›¾")
    
    print(f"å¤„ç†é€Ÿåº¦: {len(image_file_list)/batch_time:.2f}å›¾/s")
    
    if str_to_bool(args.save_visual_results):
        print(f"ğŸ–¼ï¸  å¯è§†åŒ–ç»“æœç›®å½•: {args.output_dir}")
    
    if str_to_bool(args.save_txt_results):
        print(f"ğŸ“„ æ–‡æœ¬ç»“æœç›®å½•: {args.output_dir}")
    
    print("\nâœ… å¤„ç†å®Œæˆ!")


if __name__ == "__main__":
    main() 