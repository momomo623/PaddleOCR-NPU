# -*- coding: utf-8 -*-

import os
import sys
import subprocess

__dir__ = os.path.dirname(os.path.abspath(__file__))
sys.path.append(__dir__)
sys.path.append(os.path.abspath(os.path.join(__dir__, '../..')))
from tools.infer.performance_analyzer import performance_analyzer
import cv2
import copy
import numpy as np
import time
from PIL import Image
import json
import tools.infer.pytorchocr_utility as utility
import tools.infer.predict_rec as predict_rec
import tools.infer.predict_det as predict_det
import tools.infer.predict_cls as predict_cls
from pytorchocr.utils.utility import (
    get_image_file_list,
    check_and_read,
)
from tools.infer.pytorchocr_utility import draw_ocr_box_txt


class TextSystem(object):
    def __init__(self, args, **kwargs):
        self.text_detector = predict_det.TextDetector(args, **kwargs)
        self.text_recognizer = predict_rec.TextRecognizer(args, **kwargs)
        self.use_angle_cls = args.use_angle_cls
        self.drop_score = args.drop_score
        if self.use_angle_cls:
            self.text_classifier = predict_cls.TextClassifier(args, **kwargs)

        self.args = args
        self.crop_image_res_index = 0

        # ğŸ”‘ æ™ºèƒ½é¢„ç¼©æ”¾é…ç½®
        self.enable_pre_resize = getattr(args, 'enable_pre_resize', True)
        self.max_image_pixels = getattr(args, 'max_image_pixels', 3000000)  # 300ä¸‡åƒç´ é˜ˆå€¼ï¼ˆæ›´ä¿å®ˆï¼‰
        self.min_side_after_resize = getattr(args, 'min_side_after_resize', 1400)  # ç¼©æ”¾åæœ€å°è¾¹é•¿ï¼ˆæ›´ä¿å®ˆï¼‰
        self.enable_fallback = getattr(args, 'enable_resize_fallback', True)  # å¯ç”¨å›é€€æœºåˆ¶

        # ğŸ”‘ æŒ‰éœ€æ¸è¿›å¼ç¼©æ”¾é…ç½®
        self.prefer_original_size = getattr(args, 'prefer_original_size', True)  # å¯ç”¨åŸå§‹ä¼˜å…ˆç­–ç•¥
        self.original_size_threshold = getattr(args, 'original_size_threshold', 4000000)  # åŸå§‹å›¾åƒå¤„ç†é˜ˆå€¼ (2000Ã—2000)

        # ğŸ”‘ æ”¹è¿›çš„æ¸è¿›å¼ç¼©æ”¾é…ç½®
        self.enable_progressive_resize = getattr(args, 'enable_progressive_resize', True)  # å¯ç”¨æ¸è¿›å¼ç¼©æ”¾
        self.progressive_target_range = getattr(args, 'progressive_target_range', [800, 1200])  # ç›®æ ‡å°ºå¯¸èŒƒå›´
        self.max_progressive_attempts = getattr(args, 'max_progressive_attempts', 5)  # æœ€å¤§å°è¯•æ¬¡æ•°
        self.ensure_minimum_attempt = getattr(args, 'ensure_minimum_attempt', True)  # ç¡®ä¿æœ€å°å°ºå¯¸å°è¯•
        self.aggressive_scaling_after = getattr(args, 'aggressive_scaling_after', 2)  # æ¿€è¿›ç¼©æ”¾èµ·å§‹ç‚¹
        self.maintain_aspect_ratio = getattr(args, 'maintain_aspect_ratio', True)  # ä¿æŒå®½é«˜æ¯”

        print(f"ğŸ”„ æŒ‰éœ€æ¸è¿›å¼ç¼©æ”¾é…ç½®:")
        print(f"   åŸå§‹ä¼˜å…ˆç­–ç•¥: {self.prefer_original_size}")
        print(f"   åŸå§‹å›¾åƒé˜ˆå€¼: {self.original_size_threshold:,}åƒç´  ({int(self.original_size_threshold**0.5)}Ã—{int(self.original_size_threshold**0.5)})")
        print(f"   é¢„ç¼©æ”¾é…ç½®: å¯ç”¨={self.enable_pre_resize}, åƒç´ é˜ˆå€¼={self.max_image_pixels:,}")
        print(f"   æ¸è¿›å¼ç¼©æ”¾: å¯ç”¨={self.enable_progressive_resize}, ç›®æ ‡èŒƒå›´={self.progressive_target_range}px")
        print(f"   å°è¯•é…ç½®: æœ€å¤§{self.max_progressive_attempts}æ¬¡, æ¿€è¿›ç¼©æ”¾èµ·å§‹ç¬¬{self.aggressive_scaling_after}æ¬¡")
        print(f"   ä¿æŒå®½é«˜æ¯”: {self.maintain_aspect_ratio}, ç¡®ä¿æœ€å°å°ºå¯¸: {self.ensure_minimum_attempt}")

    def smart_resize_for_ocr(self, image):
        """
        æ™ºèƒ½é¢„ç¼©æ”¾ï¼šåŸºäºåƒç´ æ•°å’Œæœ€å°è¾¹é•¿çš„åŠ¨æ€ç¼©æ”¾ç­–ç•¥

        Args:
            image: è¾“å…¥å›¾åƒ (numpy array)

        Returns:
            tuple: (ç¼©æ”¾åå›¾åƒ, ç¼©æ”¾æ¯”ä¾‹, ç¼©æ”¾ä¿¡æ¯, æ€§èƒ½ç»Ÿè®¡)
        """
        start_time = time.time()
        perf_stats = {}

        if not self.enable_pre_resize:
            elapsed = time.time() - start_time
            return image, 1.0, "disabled", {'total': elapsed}

        h, w = image.shape[:2]
        current_pixels = h * w

        # åªå¯¹è¶…å¤§å›¾åƒè¿›è¡Œç¼©æ”¾
        if current_pixels <= self.max_image_pixels:
            elapsed = time.time() - start_time
            return image, 1.0, f"no_resize({w}x{h})", {'total': elapsed}

        # è®¡ç®—åŸºäºåƒç´ æ•°çš„ç¼©æ”¾æ¯”ä¾‹
        calc_start = time.time()
        scale_ratio = (self.max_image_pixels / current_pixels) ** 0.5
        new_h, new_w = int(h * scale_ratio), int(w * scale_ratio)

        # ç¡®ä¿æœ€å°è¾¹ä¸å°äºé™åˆ¶ï¼Œä¿æŒç®­å¤´ç­‰å°ç›®æ ‡çš„å¯è¯†åˆ«æ€§
        min_current_side = min(new_h, new_w)
        if min_current_side < self.min_side_after_resize:
            adjust_ratio = self.min_side_after_resize / min_current_side
            new_h = int(new_h * adjust_ratio)
            new_w = int(new_w * adjust_ratio)
            scale_ratio *= adjust_ratio

        perf_stats['calc'] = time.time() - calc_start

        # ä½¿ç”¨INTER_AREAæ’å€¼è·å¾—æ›´å¥½çš„ç¼©æ”¾è´¨é‡
        resize_start = time.time()
        resized_image = cv2.resize(image, (new_w, new_h), interpolation=cv2.INTER_AREA)
        perf_stats['cv2_resize'] = time.time() - resize_start

        elapsed = time.time() - start_time
        perf_stats['total'] = elapsed

        resize_info = f"resize({w}x{h}->{new_w}x{new_h}, ratio={scale_ratio:.3f})"
        print(f"ğŸ”„ æ™ºèƒ½é¢„ç¼©æ”¾: {resize_info}")
        print(f"   åŸå§‹åƒç´ æ•°: {current_pixels:,}, ç›®æ ‡åƒç´ æ•°: {self.max_image_pixels:,}")
        print(f"   ç¼©æ”¾ååƒç´ æ•°: {new_w * new_h:,}, æœ€å°è¾¹é•¿: {min(new_w, new_h)}")
        print(f"   â±ï¸  æ€§èƒ½ç»Ÿè®¡: æ€»è€—æ—¶{elapsed*1000:.1f}ms (è®¡ç®—{perf_stats['calc']*1000:.1f}ms, "
              f"CV2ç¼©æ”¾{perf_stats['cv2_resize']*1000:.1f}ms)")

        return resized_image, scale_ratio, resize_info, perf_stats

    def should_use_original_size(self, image):
        """
        åˆ¤æ–­æ˜¯å¦åº”è¯¥ä½¿ç”¨åŸå§‹å›¾åƒå°ºå¯¸è¿›è¡ŒOCR
        åŸºäº2000Ã—2000åƒç´ é˜ˆå€¼ç­–ç•¥

        Args:
            image: è¾“å…¥å›¾åƒ (numpy array)

        Returns:
            tuple: (æ˜¯å¦ä½¿ç”¨åŸå§‹å°ºå¯¸, åŸå› è¯´æ˜, åˆ¤æ–­è€—æ—¶)
        """
        start_time = time.time()

        if not self.prefer_original_size:
            elapsed = time.time() - start_time
            return False, "prefer_original_size=False", elapsed

        h, w = image.shape[:2]
        total_pixels = h * w

        # æ£€æŸ¥æ˜¯å¦è¶…è¿‡åŸå§‹å›¾åƒå¤„ç†é˜ˆå€¼ï¼ˆ2000Ã—2000ï¼‰
        if total_pixels > self.original_size_threshold:
            elapsed = time.time() - start_time
            return False, f"pixels_exceed_threshold({total_pixels:,}>{self.original_size_threshold:,})", elapsed

        elapsed = time.time() - start_time
        return True, f"use_original({w}x{h}, {total_pixels:,}pixels)", elapsed

    def calculate_intelligent_target_size(self, image_shape):
        """
        æ™ºèƒ½è®¡ç®—ç›®æ ‡å°ºå¯¸ï¼Œæ ¹æ®å›¾åƒç‰¹å¾å’Œè´¨é‡åŠ¨æ€è°ƒæ•´

        Args:
            image_shape: å›¾åƒå½¢çŠ¶ (h, w, c)

        Returns:
            tuple: (ç›®æ ‡æœ€å¤§è¾¹é•¿, è®¡ç®—è€—æ—¶)
        """
        start_time = time.time()

        h, w = image_shape[:2]
        max_side = max(h, w)
        min_side = min(h, w)
        aspect_ratio = max_side / min_side

        # åŸºç¡€ç›®æ ‡å°ºå¯¸èŒƒå›´
        min_target, max_target = self.progressive_target_range

        # æ ¹æ®å›¾åƒå°ºå¯¸è°ƒæ•´ç›®æ ‡
        if max_side > 4000:
            # è¶…å¤§å›¾åƒï¼šä½¿ç”¨è¾ƒå¤§çš„ç›®æ ‡å°ºå¯¸ä¿æŒç»†èŠ‚
            target = max_target
        elif max_side > 3000:
            # å¤§å›¾åƒï¼šä½¿ç”¨ä¸­ç­‰ç›®æ ‡å°ºå¯¸
            target = (min_target + max_target) // 2
        else:
            # ä¸­ç­‰å›¾åƒï¼šä½¿ç”¨è¾ƒå°çš„ç›®æ ‡å°ºå¯¸
            target = min_target

        # æ ¹æ®å®½é«˜æ¯”è°ƒæ•´ï¼šé•¿æ¡å½¢å›¾åƒéœ€è¦æ›´å¤§çš„ç›®æ ‡å°ºå¯¸
        if aspect_ratio > 2.0:
            target = int(target * 1.2)  # å¢åŠ 20%
        elif aspect_ratio > 1.5:
            target = int(target * 1.1)  # å¢åŠ 10%

        # ç¡®ä¿ç›®æ ‡å°ºå¯¸åœ¨åˆç†èŒƒå›´å†…
        target = max(min_target, min(target, max_target))

        elapsed = time.time() - start_time
        return target, elapsed

    def progressive_resize_for_ocr(self, original_image, attempt_number):
        """
        æ”¹è¿›çš„æ¸è¿›å¼ç¼©æ”¾ï¼šç›®æ ‡å¯¼å‘çš„ç¼©æ”¾ç­–ç•¥ï¼Œç¡®ä¿èƒ½å¤Ÿæœ‰æ•ˆç¼©å°åˆ°åˆç†å°ºå¯¸

        Args:
            original_image: åŸå§‹å›¾åƒ (numpy array)
            attempt_number: å°è¯•æ¬¡æ•° (1, 2, 3, 4, 5)

        Returns:
            tuple: (ç¼©æ”¾åå›¾åƒ, ç¼©æ”¾æ¯”ä¾‹, ç¼©æ”¾ä¿¡æ¯, æ€§èƒ½ç»Ÿè®¡)
        """
        start_time = time.time()
        perf_stats = {}

        if not self.enable_progressive_resize or attempt_number > self.max_progressive_attempts:
            elapsed = time.time() - start_time
            return None, 1.0, f"progressive_disabled_or_exceeded(attempt={attempt_number})", {'total': elapsed}

        h, w = original_image.shape[:2]
        max_side = max(h, w)

        # ğŸ”‘ æ™ºèƒ½è®¡ç®—ç›®æ ‡å°ºå¯¸
        target_calc_start = time.time()
        target_size, target_calc_time = self.calculate_intelligent_target_size(original_image.shape)
        perf_stats['target_calc'] = target_calc_time

        # ğŸ”‘ ç›®æ ‡å¯¼å‘çš„ç¼©æ”¾ç­–ç•¥
        size_calc_start = time.time()
        target_max_side = self._calculate_target_oriented_size(max_side, target_size, attempt_number)
        perf_stats['size_calc'] = time.time() - size_calc_start

        # æ£€æŸ¥æ˜¯å¦å·²ç»è¶³å¤Ÿå°
        if target_max_side >= max_side:
            elapsed = time.time() - start_time
            perf_stats['total'] = elapsed
            return None, 1.0, f"no_reduction_needed({target_max_side}>={max_side})", perf_stats

        # è®¡ç®—ç¼©æ”¾æ¯”ä¾‹ï¼ˆä¸¥æ ¼ä¿æŒå®½é«˜æ¯”ï¼‰
        ratio_calc_start = time.time()
        scale_ratio = target_max_side / max_side

        if self.maintain_aspect_ratio:
            # ä¸¥æ ¼ä¿æŒå®½é«˜æ¯”
            new_h = int(h * scale_ratio)
            new_w = int(w * scale_ratio)
        else:
            # å…è®¸è½»å¾®çš„å®½é«˜æ¯”è°ƒæ•´
            new_h, new_w = int(h * scale_ratio), int(w * scale_ratio)

        # ç¡®ä¿å°ºå¯¸åˆç†
        min_size = min(self.progressive_target_range)
        if max(new_h, new_w) < min_size:
            # å¦‚æœç¼©æ”¾è¿‡å°ï¼Œè°ƒæ•´åˆ°æœ€å°ç›®æ ‡å°ºå¯¸
            if new_h > new_w:
                scale_ratio = min_size / new_h
                new_h = min_size
                new_w = int(new_w * scale_ratio)
            else:
                scale_ratio = min_size / new_w
                new_w = min_size
                new_h = int(new_h * scale_ratio)
            scale_ratio = max(new_h, new_w) / max_side

        perf_stats['ratio_calc'] = time.time() - ratio_calc_start

        # ä½¿ç”¨INTER_AREAæ’å€¼è·å¾—æ›´å¥½çš„ç¼©æ”¾è´¨é‡
        resize_start = time.time()
        resized_image = cv2.resize(original_image, (new_w, new_h), interpolation=cv2.INTER_AREA)
        perf_stats['cv2_resize'] = time.time() - resize_start

        elapsed = time.time() - start_time
        perf_stats['total'] = elapsed

        resize_info = f"progressive_resize_attempt_{attempt_number}({w}x{h}->{new_w}x{new_h}, ratio={scale_ratio:.3f})"
        print(f"ğŸ”„ æ¸è¿›å¼ç¼©æ”¾ (ç¬¬{attempt_number}æ¬¡): {resize_info}")
        print(f"   ç›®æ ‡å°ºå¯¸: {target_size}px, å½“å‰ç›®æ ‡: {target_max_side}px")
        print(f"   å®é™…ç¼©æ”¾å: {max(new_w, new_h)}px, åƒç´ æ•°: {new_w * new_h:,}")
        print(f"   å®½é«˜æ¯”ä¿æŒ: {self.maintain_aspect_ratio}, åŸå§‹æ¯”ä¾‹: {w/h:.3f}, ç¼©æ”¾åæ¯”ä¾‹: {new_w/new_h:.3f}")
        print(f"   â±ï¸  æ€§èƒ½ç»Ÿè®¡: æ€»è€—æ—¶{elapsed*1000:.1f}ms (ç›®æ ‡è®¡ç®—{target_calc_time*1000:.1f}ms, "
              f"å°ºå¯¸è®¡ç®—{perf_stats['size_calc']*1000:.1f}ms, æ¯”ä¾‹è®¡ç®—{perf_stats['ratio_calc']*1000:.1f}ms, "
              f"CV2ç¼©æ”¾{perf_stats['cv2_resize']*1000:.1f}ms)")

        return resized_image, scale_ratio, resize_info, perf_stats

    def _calculate_target_oriented_size(self, current_max_side, target_size, attempt_number):
        """
        è®¡ç®—ç›®æ ‡å¯¼å‘çš„ç¼©æ”¾å°ºå¯¸ï¼Œç¡®ä¿èƒ½å¤Ÿé€æ­¥è¾¾åˆ°ç›®æ ‡å°ºå¯¸

        Args:
            current_max_side: å½“å‰å›¾åƒæœ€å¤§è¾¹é•¿
            target_size: æœ€ç»ˆç›®æ ‡å°ºå¯¸
            attempt_number: å°è¯•æ¬¡æ•°

        Returns:
            int: æœ¬æ¬¡å°è¯•çš„ç›®æ ‡æœ€å¤§è¾¹é•¿
        """
        total_reduction_needed = current_max_side - target_size

        if total_reduction_needed <= 0:
            return current_max_side  # å·²ç»è¶³å¤Ÿå°

        # ğŸ”‘ åˆ†é˜¶æ®µç¼©æ”¾ç­–ç•¥ï¼šå‰æœŸæ¸©å’Œï¼ŒåæœŸæ¿€è¿›
        if attempt_number <= self.aggressive_scaling_after:
            # æ¸©å’Œé˜¶æ®µï¼šè¾ƒå°çš„ç¼©æ”¾å¹…åº¦
            reduction_ratios = [0.15, 0.25]  # ç¬¬1æ¬¡15%ï¼Œç¬¬2æ¬¡25%
        else:
            # æ¿€è¿›é˜¶æ®µï¼šè¾ƒå¤§çš„ç¼©æ”¾å¹…åº¦
            reduction_ratios = [0.35, 0.25, 0.25]  # ç¬¬3æ¬¡35%ï¼Œç¬¬4æ¬¡25%ï¼Œç¬¬5æ¬¡25%

        # è®¡ç®—ç´¯ç§¯ç¼©æ”¾æ¯”ä¾‹
        cumulative_reduction = 0
        for i in range(attempt_number):
            if i < len(reduction_ratios):
                cumulative_reduction += reduction_ratios[i]
            else:
                # è¶…å‡ºé¢„å®šä¹‰æ¯”ä¾‹æ—¶ï¼Œä½¿ç”¨å‰©ä½™çš„å¹³å‡åˆ†é…
                remaining_attempts = self.max_progressive_attempts - len(reduction_ratios)
                remaining_ratio = 1.0 - sum(reduction_ratios)
                cumulative_reduction += remaining_ratio / remaining_attempts

        # ç¡®ä¿ä¸è¶…è¿‡100%
        cumulative_reduction = min(cumulative_reduction, 1.0)

        # è®¡ç®—æœ¬æ¬¡ç›®æ ‡å°ºå¯¸
        target_max_side = current_max_side - int(total_reduction_needed * cumulative_reduction)

        # æœ€åä¸€æ¬¡å°è¯•æ—¶ï¼Œå¼ºåˆ¶è¾¾åˆ°ç›®æ ‡å°ºå¯¸
        if attempt_number == self.max_progressive_attempts and self.ensure_minimum_attempt:
            target_max_side = target_size

        # ç¡®ä¿ä¸å°äºæœ€å°ç›®æ ‡å°ºå¯¸
        min_target = min(self.progressive_target_range)
        target_max_side = max(target_max_side, min_target)

        return target_max_side

    def _calculate_adaptive_step_size(self, max_side, attempt_number):
        """
        è®¡ç®—è‡ªé€‚åº”æ­¥é•¿

        Args:
            max_side: å›¾åƒæœ€å¤§è¾¹é•¿
            attempt_number: å°è¯•æ¬¡æ•°

        Returns:
            int: è®¡ç®—å‡ºçš„æ­¥é•¿
        """
        base_step = self.progressive_resize_step

        # æ ¹æ®å›¾åƒå°ºå¯¸è°ƒæ•´åŸºç¡€æ­¥é•¿
        if max_side > 4000:
            # è¶…å¤§å›¾åƒï¼šä½¿ç”¨è¾ƒå¤§çš„åˆå§‹æ­¥é•¿ï¼Œä½†åç»­é€’å‡
            size_factor = 1.5
        elif max_side > 3000:
            # å¤§å›¾åƒï¼šä½¿ç”¨æ ‡å‡†æ­¥é•¿
            size_factor = 1.0
        else:
            # ä¸­ç­‰å›¾åƒï¼šä½¿ç”¨è¾ƒå°æ­¥é•¿
            size_factor = 0.7

        # æ ¹æ®å°è¯•æ¬¡æ•°è°ƒæ•´æ­¥é•¿ï¼ˆé€’å‡ç­–ç•¥ï¼‰
        if attempt_number == 1:
            # ç¬¬ä¸€æ¬¡ï¼šè¾ƒå°æ­¥é•¿ï¼Œæ¸©å’Œå°è¯•
            attempt_factor = 0.6
        elif attempt_number == 2:
            # ç¬¬äºŒæ¬¡ï¼šæ ‡å‡†æ­¥é•¿
            attempt_factor = 1.0
        elif attempt_number == 3:
            # ç¬¬ä¸‰æ¬¡ï¼šè¾ƒå¤§æ­¥é•¿ï¼Œæ›´æ¿€è¿›
            attempt_factor = 1.4
        else:
            # ç¬¬å››æ¬¡åŠä»¥åï¼šæœ€å¤§æ­¥é•¿
            attempt_factor = 1.8

        # è®¡ç®—æœ€ç»ˆæ­¥é•¿
        adaptive_step = int(base_step * size_factor * attempt_factor)

        # ç¡®ä¿æ­¥é•¿åœ¨åˆç†èŒƒå›´å†…
        min_step = 200  # æœ€å°æ­¥é•¿
        max_step = min(800, max_side // 4)  # æœ€å¤§æ­¥é•¿ä¸è¶…è¿‡å›¾åƒå°ºå¯¸çš„1/4

        adaptive_step = max(min_step, min(adaptive_step, max_step))

        return adaptive_step

    def restore_coordinates(self, dt_boxes, scale_ratio, original_shape):
        """
        å°†æ£€æµ‹æ¡†åæ ‡è¿˜åŸåˆ°åŸå§‹å›¾åƒå°ºå¯¸

        Args:
            dt_boxes: æ£€æµ‹æ¡†æ•°ç»„
            scale_ratio: ç¼©æ”¾æ¯”ä¾‹
            original_shape: åŸå§‹å›¾åƒå½¢çŠ¶ (h, w)

        Returns:
            numpy.ndarray: è¿˜åŸåçš„æ£€æµ‹æ¡†åæ ‡
        """
        if dt_boxes is None or scale_ratio == 1.0:
            return dt_boxes

        # åæ ‡è¿˜åŸï¼šé™¤ä»¥ç¼©æ”¾æ¯”ä¾‹
        restored_boxes = dt_boxes / scale_ratio

        # è¾¹ç•Œæ£€æŸ¥ï¼šç¡®ä¿åæ ‡ä¸è¶…å‡ºåŸå§‹å›¾åƒè¾¹ç•Œ
        if len(original_shape) >= 2:
            orig_h, orig_w = original_shape[:2]
            restored_boxes[:, :, 0] = np.clip(restored_boxes[:, :, 0], 0, orig_w - 1)
            restored_boxes[:, :, 1] = np.clip(restored_boxes[:, :, 1], 0, orig_h - 1)

        return restored_boxes

    def draw_crop_rec_res(self, output_dir, img_crop_list, rec_res):
        os.makedirs(output_dir, exist_ok=True)
        bbox_num = len(img_crop_list)
        for bno in range(bbox_num):
            cv2.imwrite(
                os.path.join(
                    output_dir, "mg_crop_{}.jpg".format(bno + self.crop_image_res_index)
                ),
                img_crop_list[bno],
            )
            print("{bno}, {}".format(rec_res[bno]))
        self.crop_image_res_index += bbox_num

    def __call__(self, img, cls=True, slice={}):
        time_dict = {
            "det": 0, "rec": 0, "cls": 0, "all": 0,
            "resize": 0, "progressive": 0, "fallback": 0, "original": 0,
            # è¯¦ç»†çš„æ€§èƒ½åˆ†ç±»
            "size_judgment": 0, "smart_resize": 0, "progressive_attempts": 0,
            "resize_calc": 0, "cv2_resize": 0, "target_calc": 0
        }

        if img is None:
            print("no valid image provided")
            return None, None, time_dict

        start = time.time()
        ori_im = img.copy()
        original_shape = ori_im.shape

        # ğŸ”‘ æŒ‰éœ€æ¸è¿›å¼ç¼©æ”¾ç­–ç•¥ï¼šå†³å®šå¤„ç†é¡ºåº
        judgment_start = time.time()
        use_original, reason, judgment_time = self.should_use_original_size(ori_im)
        time_dict["size_judgment"] = judgment_time

        if use_original:
            print(f"ğŸ¯ é‡‡ç”¨åŸå§‹ä¼˜å…ˆç­–ç•¥: {reason} (åˆ¤æ–­è€—æ—¶: {judgment_time*1000:.1f}ms)")
            # åŸå§‹ä¼˜å…ˆæ¨¡å¼ï¼šå…ˆå°è¯•åŸå§‹å›¾åƒ
            img, scale_ratio, resize_info = ori_im, 1.0, "original_size_first"
            time_dict["resize"] = 0
        else:
            print(f"ğŸ”„ é‡‡ç”¨é¢„ç¼©æ”¾ä¼˜å…ˆç­–ç•¥: {reason} (åˆ¤æ–­è€—æ—¶: {judgment_time*1000:.1f}ms)")
            # é¢„ç¼©æ”¾ä¼˜å…ˆæ¨¡å¼ï¼šå…ˆè¿›è¡Œæ™ºèƒ½é¢„ç¼©æ”¾
            resize_start = time.time()
            img, scale_ratio, resize_info, resize_perf = self.smart_resize_for_ocr(img)
            time_dict["resize"] = time.time() - resize_start
            time_dict["smart_resize"] = resize_perf.get('total', 0)
            time_dict["resize_calc"] += resize_perf.get('calc', 0)
            time_dict["cv2_resize"] += resize_perf.get('cv2_resize', 0)

        if slice:
            slice_gen = utility.slice_generator(
                img,
                horizontal_stride=slice["horizontal_stride"],
                vertical_stride=slice["vertical_stride"],
            )
            elapsed = []
            dt_slice_boxes = []

            for slice_crop, v_start, h_start in slice_gen:
                dt_boxes, elapse = self.text_detector(slice_crop, use_slice=True)
                if dt_boxes.size:
                    dt_boxes[:, :, 0] += h_start
                    dt_boxes[:, :, 1] += v_start
                    dt_slice_boxes.append(dt_boxes)
                    elapsed.append(elapse)

            if dt_slice_boxes:
                dt_boxes = np.concatenate(dt_slice_boxes)
                dt_boxes = utility.merge_fragmented(
                    boxes=dt_boxes,
                    x_threshold=slice["merge_x_thres"],
                    y_threshold=slice["merge_y_thres"],
                )
            else:
                dt_boxes = np.array([])
            elapse = sum(elapsed)
        else:
            dt_boxes, elapse = self.text_detector(img)

        time_dict["det"] = elapse

        # ğŸ”‘ æ¸è¿›å¼ç¼©æ”¾æœºåˆ¶ï¼šå¦‚æœåˆæ¬¡ç¼©æ”¾åæ£€æµ‹å¤±è´¥ï¼Œå°è¯•æ›´æ¿€è¿›çš„ç¼©æ”¾
        progressive_attempt = 1
        progressive_start_time = time.time()

        while ((dt_boxes is None or len(dt_boxes) == 0) and
               progressive_attempt <= self.max_progressive_attempts and
               self.enable_progressive_resize):

            print(f"âš ï¸  ç¬¬{progressive_attempt-1 if progressive_attempt > 1 else 'åˆæ¬¡'}ç¼©æ”¾æœªæ£€æµ‹åˆ°æ–‡æœ¬ï¼Œå°è¯•æ¸è¿›å¼ç¼©æ”¾...")

            # è¿›è¡Œæ¸è¿›å¼ç¼©æ”¾
            progressive_img, progressive_scale_ratio, progressive_resize_info, progressive_perf = self.progressive_resize_for_ocr(
                ori_im, progressive_attempt
            )

            # ç´¯ç§¯æ¸è¿›å¼ç¼©æ”¾çš„æ€§èƒ½ç»Ÿè®¡
            time_dict["progressive_attempts"] += progressive_perf.get('total', 0)
            time_dict["target_calc"] += progressive_perf.get('target_calc', 0)
            time_dict["resize_calc"] += progressive_perf.get('size_calc', 0) + progressive_perf.get('ratio_calc', 0)
            time_dict["cv2_resize"] += progressive_perf.get('cv2_resize', 0)

            if progressive_img is None:
                print(f"âŒ æ¸è¿›å¼ç¼©æ”¾ç¬¬{progressive_attempt}æ¬¡å¤±è´¥: è¾¾åˆ°é™åˆ¶æ¡ä»¶")
                break

            # ä½¿ç”¨æ¸è¿›å¼ç¼©æ”¾åçš„å›¾åƒè¿›è¡Œæ£€æµ‹
            if slice:
                slice_gen = utility.slice_generator(
                    progressive_img,
                    horizontal_stride=slice["horizontal_stride"],
                    vertical_stride=slice["vertical_stride"],
                )
                elapsed = []
                dt_slice_boxes = []

                for slice_crop, v_start, h_start in slice_gen:
                    dt_boxes, elapse = self.text_detector(slice_crop, use_slice=True)
                    if dt_boxes.size:
                        dt_boxes[:, :, 0] += h_start
                        dt_boxes[:, :, 1] += v_start
                        dt_slice_boxes.append(dt_boxes)
                        elapsed.append(elapse)

                if dt_slice_boxes:
                    dt_boxes = np.concatenate(dt_slice_boxes)
                    dt_boxes = utility.merge_fragmented(
                        boxes=dt_boxes,
                        x_threshold=slice["merge_x_thres"],
                        y_threshold=slice["merge_y_thres"],
                    )
                else:
                    dt_boxes = np.array([])
                elapse = sum(elapsed)
            else:
                dt_boxes, elapse = self.text_detector(progressive_img)

            time_dict["det"] += elapse  # ç´¯åŠ æ£€æµ‹æ—¶é—´

            if dt_boxes is not None and len(dt_boxes) > 0:
                print(f"âœ… æ¸è¿›å¼ç¼©æ”¾ç¬¬{progressive_attempt}æ¬¡æˆåŠŸ: æ£€æµ‹åˆ° {len(dt_boxes)} ä¸ªæ–‡æœ¬åŒºåŸŸ")
                # æ›´æ–°ç¼©æ”¾ä¿¡æ¯å’Œæ¯”ä¾‹
                scale_ratio = progressive_scale_ratio
                resize_info += f" -> {progressive_resize_info}"
                img = progressive_img  # æ›´æ–°å½“å‰ä½¿ç”¨çš„å›¾åƒ
                break
            else:
                print(f"âŒ æ¸è¿›å¼ç¼©æ”¾ç¬¬{progressive_attempt}æ¬¡ä»ç„¶å¤±è´¥")
                progressive_attempt += 1

        time_dict["progressive"] = time.time() - progressive_start_time

        # ğŸ”‘ æœ€ç»ˆå›é€€æœºåˆ¶ï¼šå¦‚æœæ¸è¿›å¼ç¼©æ”¾éƒ½å¤±è´¥ï¼Œå°è¯•ä½¿ç”¨åŸå§‹å›¾åƒ
        if ((dt_boxes is None or len(dt_boxes) == 0) and
            scale_ratio != 1.0 and self.enable_fallback):

            print("âš ï¸  æ¸è¿›å¼ç¼©æ”¾å…¨éƒ¨å¤±è´¥ï¼Œæœ€ç»ˆå›é€€åˆ°åŸå§‹å›¾åƒ...")
            fallback_start = time.time()

            # ä½¿ç”¨åŸå§‹å›¾åƒé‡æ–°æ£€æµ‹
            if slice:
                slice_gen = utility.slice_generator(
                    ori_im,
                    horizontal_stride=slice["horizontal_stride"],
                    vertical_stride=slice["vertical_stride"],
                )
                elapsed = []
                dt_slice_boxes = []

                for slice_crop, v_start, h_start in slice_gen:
                    dt_boxes, elapse = self.text_detector(slice_crop, use_slice=True)
                    if dt_boxes.size:
                        dt_boxes[:, :, 0] += h_start
                        dt_boxes[:, :, 1] += v_start
                        dt_slice_boxes.append(dt_boxes)
                        elapsed.append(elapse)

                if dt_slice_boxes:
                    dt_boxes = np.concatenate(dt_slice_boxes)
                    dt_boxes = utility.merge_fragmented(
                        boxes=dt_boxes,
                        x_threshold=slice["merge_x_thres"],
                        y_threshold=slice["merge_y_thres"],
                    )
                else:
                    dt_boxes = np.array([])
                elapse = sum(elapsed)
            else:
                dt_boxes, elapse = self.text_detector(ori_im)

            time_dict["fallback"] = time.time() - fallback_start
            time_dict["det"] += elapse  # ç´¯åŠ æ£€æµ‹æ—¶é—´
            scale_ratio = 1.0  # é‡ç½®ç¼©æ”¾æ¯”ä¾‹
            resize_info += " -> final_fallback_to_original"

            if dt_boxes is not None and len(dt_boxes) > 0:
                print(f"âœ… æœ€ç»ˆå›é€€æˆåŠŸ: æ£€æµ‹åˆ° {len(dt_boxes)} ä¸ªæ–‡æœ¬åŒºåŸŸ")
            else:
                print("âŒ æœ€ç»ˆå›é€€ä»ç„¶å¤±è´¥")

        # ğŸ”‘ åæ ‡è¿˜åŸï¼šå°†æ£€æµ‹æ¡†åæ ‡è¿˜åŸåˆ°åŸå§‹å›¾åƒå°ºå¯¸
        if dt_boxes is not None and len(dt_boxes) > 0:
            dt_boxes = self.restore_coordinates(dt_boxes, scale_ratio, original_shape)

        if dt_boxes is None or len(dt_boxes) == 0:
            print("no dt_boxes found, elapsed : {}, resize_info: {}".format(elapse, resize_info))
            end = time.time()
            time_dict["all"] = end - start
            return None, None, time_dict
        else:
            print(
                "dt_boxes num : {}, elapsed : {}, resize_info: {}".format(len(dt_boxes), elapse, resize_info)
            )

        img_crop_list = []

        dt_boxes = sorted_boxes(dt_boxes)

        for bno in range(len(dt_boxes)):
            tmp_box = copy.deepcopy(dt_boxes[bno])
            if self.args.det_box_type == "quad":
                img_crop = utility.get_rotate_crop_image(ori_im, tmp_box)
            else:
                img_crop = utility.get_minarea_rect_crop(ori_im, tmp_box)
            img_crop_list.append(img_crop)
        if self.use_angle_cls and cls:
            img_crop_list, angle_list, elapse = self.text_classifier(
                img_crop_list)
            time_dict["cls"] = elapse
            print("cls num  : {}, elapse : {}".format(
                len(img_crop_list), elapse))

        if len(img_crop_list) > 1000:
            print(
                "rec crops num: {}, time and memory cost may be large.".format(len(img_crop_list))
            )

        rec_res, elapse = self.text_recognizer(img_crop_list)
        time_dict["rec"] = elapse
        print("rec_res num  : {}, elapse : {}".format(
            len(rec_res), elapse))
        if self.args.save_crop_res:
            self.draw_crop_rec_res(self.args.crop_res_save_dir, img_crop_list, rec_res)
        filter_boxes, filter_rec_res = [], []

        print(f"self.drop_score åˆ†æ•°çº¿ : {self.drop_score}")
        for box, rec_reuslt in zip(dt_boxes, rec_res):
            text, score = rec_reuslt
            if score >= self.drop_score:
                filter_boxes.append(box)
                filter_rec_res.append(rec_reuslt)
            else:
                print(f"drop_score: {score}, text: {text}")
        end = time.time()
        time_dict["all"] = end - start

        # ğŸ”‘ è¯¦ç»†æ€§èƒ½æŠ¥å‘Š
        self._print_performance_report(time_dict, resize_info)

        return filter_boxes, filter_rec_res, time_dict

    def _print_performance_report(self, time_dict, resize_info):
        """æ‰“å°è¯¦ç»†çš„æ€§èƒ½æŠ¥å‘Š"""
        total_time = time_dict["all"]

        print(f"\nğŸ“Š æ€§èƒ½åˆ†ææŠ¥å‘Š (æ€»è€—æ—¶: {total_time:.3f}s)")
        print("=" * 50)

        # ç¼©æ”¾ç›¸å…³æ€§èƒ½
        resize_total = (time_dict["size_judgment"] + time_dict["smart_resize"] +
                       time_dict["progressive_attempts"] + time_dict["fallback"])

        if resize_total > 0:
            print(f"ğŸ”„ ç¼©æ”¾å¤„ç†: {resize_total:.3f}s ({resize_total/total_time*100:.1f}%)")
            if time_dict["size_judgment"] > 0:
                print(f"   - å°ºå¯¸åˆ¤æ–­: {time_dict['size_judgment']*1000:.1f}ms")
            if time_dict["smart_resize"] > 0:
                print(f"   - æ™ºèƒ½é¢„ç¼©æ”¾: {time_dict['smart_resize']*1000:.1f}ms")
            if time_dict["progressive_attempts"] > 0:
                print(f"   - æ¸è¿›å¼ç¼©æ”¾: {time_dict['progressive_attempts']*1000:.1f}ms")
            if time_dict["fallback"] > 0:
                print(f"   - å›é€€å¤„ç†: {time_dict['fallback']*1000:.1f}ms")

        # ç¼©æ”¾ç»†èŠ‚æ€§èƒ½
        detail_total = time_dict["target_calc"] + time_dict["resize_calc"] + time_dict["cv2_resize"]
        if detail_total > 0:
            print(f"ğŸ”§ ç¼©æ”¾ç»†èŠ‚: {detail_total:.3f}s ({detail_total/total_time*100:.1f}%)")
            if time_dict["target_calc"] > 0:
                print(f"   - ç›®æ ‡è®¡ç®—: {time_dict['target_calc']*1000:.1f}ms")
            if time_dict["resize_calc"] > 0:
                print(f"   - å°ºå¯¸è®¡ç®—: {time_dict['resize_calc']*1000:.1f}ms")
            if time_dict["cv2_resize"] > 0:
                print(f"   - CV2ç¼©æ”¾: {time_dict['cv2_resize']*1000:.1f}ms")

        # OCRæ ¸å¿ƒæ€§èƒ½
        ocr_total = time_dict["det"] + time_dict["rec"] + time_dict["cls"]
        print(f"ğŸ” OCRæ ¸å¿ƒ: {ocr_total:.3f}s ({ocr_total/total_time*100:.1f}%)")
        print(f"   - æ–‡æœ¬æ£€æµ‹: {time_dict['det']*1000:.1f}ms")
        print(f"   - æ–‡æœ¬è¯†åˆ«: {time_dict['rec']*1000:.1f}ms")
        if time_dict["cls"] > 0:
            print(f"   - è§’åº¦åˆ†ç±»: {time_dict['cls']*1000:.1f}ms")

        # æ€§èƒ½å»ºè®®
        if resize_total > ocr_total:
            print(f"\nâš ï¸  ç¼©æ”¾å¤„ç†è€—æ—¶({resize_total:.3f}s)è¶…è¿‡OCRæ ¸å¿ƒ({ocr_total:.3f}s)")
            print(f"   å»ºè®®: è€ƒè™‘è°ƒæ•´ç¼©æ”¾ç­–ç•¥æˆ–é˜ˆå€¼å‚æ•°")

        if time_dict["progressive_attempts"] > 0.1:
            print(f"\nğŸ’¡ æ¸è¿›å¼ç¼©æ”¾è€—æ—¶è¾ƒé•¿({time_dict['progressive_attempts']:.3f}s)")
            print(f"   å»ºè®®: è€ƒè™‘å‡å°‘å°è¯•æ¬¡æ•°æˆ–è°ƒæ•´ç›®æ ‡å°ºå¯¸èŒƒå›´")

        print(f"\nğŸ“‹ å¤„ç†ç­–ç•¥: {resize_info}")
        print("=" * 50)


def sorted_boxes(dt_boxes):
    """
    Sort text boxes in order from top to bottom, left to right
    args:
        dt_boxes(array):detected text boxes with shape [4, 2]
    return:
        sorted boxes(array) with shape [4, 2]
    """
    num_boxes = dt_boxes.shape[0]
    sorted_boxes = sorted(dt_boxes, key=lambda x: (x[0][1], x[0][0]))
    _boxes = list(sorted_boxes)

    for i in range(num_boxes - 1):
        if abs(_boxes[i + 1][0][1] - _boxes[i][0][1]) < 10 and \
                (_boxes[i + 1][0][0] < _boxes[i][0][0]):
            tmp = _boxes[i]
            _boxes[i] = _boxes[i + 1]
            _boxes[i + 1] = tmp
    return _boxes


def main(args):
    image_file_list = get_image_file_list(args.image_dir)
    text_sys = TextSystem(args)
    is_visualize = True
    font_path = args.vis_font_path
    drop_score = args.drop_score
    draw_img_save_dir = args.draw_img_save_dir
    os.makedirs(draw_img_save_dir, exist_ok=True)

    save_results = []
    total_time = 0
    _st = time.time()
    if args.enable_perf_analysis:
        device_info = getattr(text_sys.text_detector, 'device_type', 'unknown')
        performance_analyzer.start_batch(device_info)

    for idx, image_file in enumerate(image_file_list):
        img, flag_gif, flag_pdf = check_and_read(image_file)
        if not flag_gif and not flag_pdf:
            img = cv2.imread(image_file)
        if not flag_pdf:
            if img is None:
                print("error in loading image:{}".format(image_file))
                continue
            imgs = [img]
        else:
            page_num = args.page_num
            if page_num > len(img) or page_num == 0:
                page_num = len(img)
            imgs = img[:page_num]

        for index, img in enumerate(imgs):
            starttime = time.time()
            dt_boxes, rec_res, time_dict = text_sys(img)
            elapse = time.time() - starttime

            # è®°å½•æ€§èƒ½æ•°æ®
            if args.enable_perf_analysis:
                img_path = f"{image_file}_{index}" if len(imgs) > 1 else image_file
                img_size = f"{img.shape[1]}x{img.shape[0]}"  # width x height
                text_count = len(rec_res) if rec_res else 0
                performance_analyzer.record_image(img_path, time_dict, img_size, text_count)

            if len(imgs) > 1:
                print(
                    str(idx)
                    + "_"
                    + str(index)
                    + "  Predict time of %s: %.3fs" % (image_file, elapse)
                )
            else:
                print(
                    str(idx) + "  Predict time of %s: %.3fs" % (image_file, elapse)
                )

            # ğŸ”‘ ä¿®å¤ï¼šæ£€æŸ¥ rec_res æ˜¯å¦ä¸º None
            if rec_res is not None and len(rec_res) > 0:
                for text, score in rec_res:
                    print("{}, {:.3f}".format(text, score))

                res = [
                    {
                        "transcription": rec_res[i][0],
                        "points": np.array(dt_boxes[i]).astype(np.int32).tolist(),
                    }
                    for i in range(len(dt_boxes))
                ]
            else:
                print("âš ï¸  æœªæ£€æµ‹åˆ°ä»»ä½•æ–‡æœ¬å†…å®¹")
                res = []
            if len(imgs) > 1:
                save_pred = (
                        os.path.basename(image_file)
                        + "_"
                        + str(index)
                        + "\t"
                        + json.dumps(res, ensure_ascii=False)
                        + "\n"
                )
            else:
                save_pred = (
                        os.path.basename(image_file)
                        + "\t"
                        + json.dumps(res, ensure_ascii=False)
                        + "\n"
                )
            save_results.append(save_pred)

            if is_visualize:
                image = Image.fromarray(cv2.cvtColor(img, cv2.COLOR_BGR2RGB))
                boxes = dt_boxes
                txts = [rec_res[i][0] for i in range(len(rec_res))]
                scores = [rec_res[i][1] for i in range(len(rec_res))]

                draw_img = draw_ocr_box_txt(
                    image,
                    boxes,
                    txts,
                    scores,
                    drop_score=drop_score,
                    font_path=font_path,
                )

                if flag_gif:
                    save_file = image_file[:-3] + "png"
                elif flag_pdf:
                    save_file = image_file.replace(".pdf", "_" + str(index) + ".png")
                else:
                    save_file = image_file
                cv2.imwrite(
                    os.path.join(draw_img_save_dir, os.path.basename(save_file)),
                    draw_img[:, :, ::-1],
                )

                print(
                    "The visualized image saved in {}".format(
                        os.path.join(draw_img_save_dir, os.path.basename(save_file))
                    )
                )

    print("The predict total time is {}".format(time.time() - _st))

    # ç”Ÿæˆæ€§èƒ½åˆ†ææŠ¥å‘Š
    if args.enable_perf_analysis:
        performance_analyzer.end_batch()
        performance_analyzer.save_detailed_report(args.perf_report_path)

    with open(
            os.path.join(draw_img_save_dir, "system_results.txt"), "w", encoding="utf-8"
    ) as f:
        f.writelines(save_results)


if __name__ == '__main__':
    args = utility.parse_args()
    if args.use_mp:
        p_list = []
        total_process_num = args.total_process_num
        for process_id in range(total_process_num):
            cmd = (
                    [sys.executable, "-u"]
                    + sys.argv
                    + ["--process_id={}".format(process_id), "--use_mp={}".format(False)]
            )
            p = subprocess.Popen(cmd, stdout=sys.stdout, stderr=sys.stdout)
            p_list.append(p)
        for p in p_list:
            p.wait()
    else:
        main(args)